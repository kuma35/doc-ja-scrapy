# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008–2018, Scrapy developers
# This file is distributed under the same license as the Scrapy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Scrapy \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-09-10 09:37+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../topics/item-pipeline.rst:5
msgid "Item Pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:7
msgid ""
"After an item has been scraped by a spider, it is sent to the Item "
"Pipeline which processes it through several components that are executed "
"sequentially."
msgstr ""

#: ../../topics/item-pipeline.rst:10
msgid ""
"Each item pipeline component (sometimes referred as just \"Item "
"Pipeline\") is a Python class that implements a simple method. They "
"receive an item and perform an action over it, also deciding if the item "
"should continue through the pipeline or be dropped and no longer "
"processed."
msgstr ""

#: ../../topics/item-pipeline.rst:15
msgid "Typical uses of item pipelines are:"
msgstr ""

#: ../../topics/item-pipeline.rst:17
msgid "cleansing HTML data"
msgstr ""

#: ../../topics/item-pipeline.rst:18
msgid "validating scraped data (checking that the items contain certain fields)"
msgstr ""

#: ../../topics/item-pipeline.rst:19
msgid "checking for duplicates (and dropping them)"
msgstr ""

#: ../../topics/item-pipeline.rst:20
msgid "storing the scraped item in a database"
msgstr ""

#: ../../topics/item-pipeline.rst:24
msgid "Writing your own item pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:26
msgid ""
"Each item pipeline component is a Python class that must implement the "
"following method:"
msgstr ""

#: ../../topics/item-pipeline.rst:30
msgid ""
"This method is called for every item pipeline component. "
":meth:`process_item` must either: return a dict with data, return an "
":class:`~scrapy.item.Item` (or any descendant class) object, return a "
"`Twisted Deferred`_ or raise :exc:`~scrapy.exceptions.DropItem` "
"exception. Dropped items are no longer processed by further pipeline "
"components."
msgstr ""

#: ../../topics/item-pipeline.rst
msgid "パラメータ"
msgstr ""

#: ../../topics/item-pipeline.rst:36
msgid "the item scraped"
msgstr ""

#: ../../topics/item-pipeline.rst:39
msgid "the spider which scraped the item"
msgstr ""

#: ../../topics/item-pipeline.rst:42
msgid "Additionally, they may also implement the following methods:"
msgstr ""

#: ../../topics/item-pipeline.rst:46
msgid "This method is called when the spider is opened."
msgstr ""

#: ../../topics/item-pipeline.rst:48
msgid "the spider which was opened"
msgstr ""

#: ../../topics/item-pipeline.rst:53
msgid "This method is called when the spider is closed."
msgstr ""

#: ../../topics/item-pipeline.rst:55
msgid "the spider which was closed"
msgstr ""

#: ../../topics/item-pipeline.rst:60
msgid ""
"If present, this classmethod is called to create a pipeline instance from"
" a :class:`~scrapy.crawler.Crawler`. It must return a new instance of the"
" pipeline. Crawler object provides access to all Scrapy core components "
"like settings and signals; it is a way for pipeline to access them and "
"hook its functionality into Scrapy."
msgstr ""

#: ../../topics/item-pipeline.rst:66
msgid "crawler that uses this pipeline"
msgstr ""

#: ../../topics/item-pipeline.rst:73
msgid "Item pipeline example"
msgstr ""

#: ../../topics/item-pipeline.rst:76
msgid "Price validation and dropping items with no prices"
msgstr ""

#: ../../topics/item-pipeline.rst:78
msgid ""
"Let's take a look at the following hypothetical pipeline that adjusts the"
" ``price`` attribute for those items that do not include VAT "
"(``price_excludes_vat`` attribute), and drops those items which don't "
"contain a price::"
msgstr ""

#: ../../topics/item-pipeline.rst:99
msgid "Write items to a JSON file"
msgstr ""

#: ../../topics/item-pipeline.rst:101
msgid ""
"The following pipeline stores all scraped items (from all spiders) into a"
" single ``items.jl`` file, containing one item per line serialized in "
"JSON format::"
msgstr ""

#: ../../topics/item-pipeline.rst:120
msgid ""
"The purpose of JsonWriterPipeline is just to introduce how to write item "
"pipelines. If you really want to store all scraped items into a JSON file"
" you should use the :ref:`Feed exports <topics-feed-exports>`."
msgstr ""

#: ../../topics/item-pipeline.rst:125
msgid "Write items to MongoDB"
msgstr ""

#: ../../topics/item-pipeline.rst:127
msgid ""
"In this example we'll write items to MongoDB_ using pymongo_. MongoDB "
"address and database name are specified in Scrapy settings; MongoDB "
"collection is named after item class."
msgstr ""

#: ../../topics/item-pipeline.rst:131
msgid ""
"The main point of this example is to show how to use :meth:`from_crawler`"
" method and how to clean up the resources properly.::"
msgstr ""

#: ../../topics/item-pipeline.rst:167
msgid "Take screenshot of item"
msgstr ""

#: ../../topics/item-pipeline.rst:169
msgid ""
"This example demonstrates how to return Deferred_ from "
":meth:`process_item` method. It uses Splash_ to render screenshot of item"
" url. Pipeline makes request to locally running instance of Splash_. "
"After request is downloaded and Deferred callback fires, it saves item to"
" a file and adds filename to an item."
msgstr ""

#: ../../topics/item-pipeline.rst:215
msgid "Duplicates filter"
msgstr ""

#: ../../topics/item-pipeline.rst:217
msgid ""
"A filter that looks for duplicate items, and drops those items that were "
"already processed. Let's say that our items have a unique id, but our "
"spider returns multiples items with the same id::"
msgstr ""

#: ../../topics/item-pipeline.rst:238
msgid "Activating an Item Pipeline component"
msgstr ""

#: ../../topics/item-pipeline.rst:240
msgid ""
"To activate an Item Pipeline component you must add its class to the "
":setting:`ITEM_PIPELINES` setting, like in the following example::"
msgstr ""

#: ../../topics/item-pipeline.rst:248
msgid ""
"The integer values you assign to classes in this setting determine the "
"order in which they run: items go through from lower valued to higher "
"valued classes. It's customary to define these numbers in the 0-1000 "
"range."
msgstr ""

